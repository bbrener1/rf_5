{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Existence Of Node Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate that in random forest that has been trained on some set of data, the nodes can be reasonably organized into clusters.\n",
    "\n",
    "First, we must train or load a forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GSE129788_RAW.tar                       cv_forest_trimmed\r\n",
      "GSM3722100_YX1L_10X.txt                 cv_forest_trimmed_extra\r\n",
      "GSM3722101_YX2L_10X.txt                 cv_forest_trimmed_extra_1\r\n",
      "GSM3722102_YX3R_10X.txt                 cv_forest_trimmed_extra_10\r\n",
      "GSM3722103_YX4R_10X.txt                 cv_forest_trimmed_extra_2\r\n",
      "GSM3722104_YX5R_10X.txt                 cv_forest_trimmed_extra_3\r\n",
      "GSM3722105_YX6L_10X.txt                 cv_forest_trimmed_extra_4\r\n",
      "GSM3722106_YX7R_10X.txt                 cv_forest_trimmed_extra_5\r\n",
      "GSM3722107_YX8L_10X.txt                 cv_forest_trimmed_extra_5_cached\r\n",
      "GSM3722108_OX1X_10X.txt                 cv_forest_trimmed_extra_5_cached_great\r\n",
      "GSM3722109_OX2X_10X.txt                 cv_forest_trimmed_extra_5_cachked_great\r\n",
      "GSM3722110_OX3X_10X.txt                 cv_forest_trimmed_extra_6\r\n",
      "GSM3722111_OX4X_10X.txt                 cv_forest_trimmed_extra_7\r\n",
      "GSM3722112_OX5X_10X.txt                 cv_forest_trimmed_extra_8\r\n",
      "GSM3722113_OX6X_10X.txt                 cv_forest_trimmed_extra_9\r\n",
      "GSM3722114_OX7X_10X.txt                 cv_forest_trimmed_extra_new\r\n",
      "GSM3722115_OX8X_10X.txt                 full_clustering\r\n",
      "SRR8895023_1.fastq.gz                   full_clustering_predicted\r\n",
      "SRR8895024_1.fastq.gz                   full_clustering_predicted_trimmed\r\n",
      "SRR8895025_1.fastq.gz                   full_custering_predicted\r\n",
      "SRR8895026_1.fastq.gz                   full_custering_predicted_cached\r\n",
      "SRR8895027_1.fastq.gz                   \u001b[34mrestricted_sub_forest\u001b[m\u001b[m\r\n",
      "SRR8895028_1.fastq.gz                   scanpy_aging_brain.ipynb\r\n",
      "SRR8895029_1.fastq.gz                   scanpy_aging_brain_3.ipynb\r\n",
      "SRR8895030_1.fastq.gz                   scanpy_aging_brain_cv_forest\r\n",
      "SRR8895031_1.fastq                      scanpy_aging_brain_cv_forest_compact\r\n",
      "SRR8895031_1.fastq.gz                   scanpy_aging_brain_random_cv_forest\r\n",
      "SRR8895032_1.fastq.gz                   scanpy_aging_brain_restricted_1\r\n",
      "SRR8895033_1.fastq.gz                   scanpy_aging_brain_restricted_2\r\n",
      "SRR8895034_1.fastq.gz                   scanpy_cmp_aging_brain_compact\r\n",
      "SRR8895035_1.fastq.gz                   scanpy_cmp_aging_brain_deep\r\n",
      "SRR8895036_1.fastq.gz                   scanpy_cmp_aging_brain_fine\r\n",
      "SRR8895037_1.fastq.gz                   scanpy_cmp_aging_brain_trim\r\n",
      "SRR8895038_1.fastq.gz                   scanpy_cmp_aging_brain_trim_prediction\r\n",
      "aging_batch_encoding.tsv                scanpy_cmp_aging_brain_true_l1\r\n",
      "aging_brain_filtered.pickle             scanpy_cmp_aging_small_deep\r\n",
      "aging_brain_old.pickle                  scanpy_cmp_aging_small_deep_sfr0\r\n",
      "aging_brain_young.pickle                scanpy_cmp_aging_small_deep_sfr0_l1\r\n",
      "cv_forest                               scanpy_cmp_aging_small_deep_sfr0_l1_v2\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/Users/bbrener1/battle/rusty_forest_4/target/release/rusty_lumberjack_v3',\n",
       " '-ic',\n",
       " '/var/folders/_k/81hqlgss0tbf2l0t7wm4t_200000gn/T/tmp1p802p8o/input.counts',\n",
       " '-oc',\n",
       " '/var/folders/_k/81hqlgss0tbf2l0t7wm4t_200000gn/T/tmp1p802p8o/output.counts',\n",
       " '-o',\n",
       " '/var/folders/_k/81hqlgss0tbf2l0t7wm4t_200000gn/T/tmp1p802p8o/tmp',\n",
       " '-auto',\n",
       " '-ifh',\n",
       " '/var/folders/_k/81hqlgss0tbf2l0t7wm4t_200000gn/T/tmp1p802p8o/tmp.ifh',\n",
       " '-ofh',\n",
       " '/var/folders/_k/81hqlgss0tbf2l0t7wm4t_200000gn/T/tmp1p802p8o/tmp.ofh',\n",
       " '-trees',\n",
       " '100',\n",
       " '-braids',\n",
       " '2',\n",
       " '-ifs',\n",
       " '150',\n",
       " '-ofs',\n",
       " '150',\n",
       " '-ss',\n",
       " '500',\n",
       " '-depth',\n",
       " '8',\n",
       " '-leaves',\n",
       " '10',\n",
       " '-sfr',\n",
       " '0',\n",
       " '-norm',\n",
       " 'l1',\n",
       " '-reduce_input',\n",
       " 'true',\n",
       " '-reduce_output',\n",
       " 'false']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy as sc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/python')\n",
    "import tree_reader as tr \n",
    "import lumberjack\n",
    "\n",
    "data_location = \"/Users/bbrener1/battle/rusty_forest_4/data/aging_brain/\"\n",
    "!ls {data_location}\n",
    "# data_location = \"../data/aging_brain/\"\n",
    "\n",
    "forest = tr.Forest.load(data_location + 'cv_forest_trimmed_extra')\n",
    "forest.arguments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "39\n",
      "14082\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(forest.output_features))\n",
    "print(len(forest.split_clusters))\n",
    "print(len(forest.nodes()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest is a collection of decision trees, and a decision tree is a collection of individual decision points, commonly known as \"Nodes\"\n",
    "\n",
    "To understand Random Forests and Decision Trees, it is important to understand how Nodes work. Each individual node is a (very crappy) regressor, eg. each Node makess a prediction based on a rule like \"If Gene 1 has expression > 10, Gene 2 will have expression < 5\", or \"If a house is < 5 miles from a school, it will cost > $100,000\". A very important property of each node, however, is that it can also have children, which are other nodes. When a node makes a prediction like \"If Gene 1 has expression > 10 then Gene 2 has expression < 5\", it can pass all the samples for which Gene 1 is > 10 to one of its children, and all the samples for which Gene 1 < 10 to the other child. After that, each one of its children can make a different prediction, which results in compound rules.\n",
    "\n",
    "This is how a decision tree is formed. A decision tree with a depth of 2 might contain a rule like \"If Gene 1 > 10 AND Gene 3 > 10, THEN Gene 2 and Gene 4 are both < 2, which would represent one of the \"Leaf\" nodes that it has. Leaf nodes are nodes with no children. \n",
    "\n",
    "Individual decision trees, then, are somewhat crappy predictors, but they're better than individual nodes. In order to improve the performance of decision trees, we can construct a Random Forest. To construct a random forest, we can train many decision trees on bootstraps of a dataset\n",
    "\n",
    "If many decision trees are combined and their predictions averaged together, you have a Random Forest, which is a pretty good kind of regressor. \n",
    "\n",
    "A practical demonstration might help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.reset_split_clusters()\n",
    "forest.interpret_splits(depth=5,mode='additive_mean',metric='cosine',pca=100,relatives=True,k=10,resolution=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we know that random forests are collections of ordered nodes, we can examine a more interesting question: do certain nodes occur repeatedly in the forest, despite operating on bootstrapped samples? \n",
    "\n",
    "In order to examine this question first we must understand different ways of describing a node. I think generally there are three helpful ways of looking at a node:\n",
    "\n",
    "* **Node Sample Encoding**: A binary vector the length of the number of samples you are considering. 0 or false means the sample is absent from the node. A 1 or true means the sample is present in the node. \n",
    "\n",
    "* **Node Mean Encoding**: A float vector the length of the number of targets you are considering. Each value is the mean of the target values for all samples in this node. This is the node's prediction for samples that occur in it.\n",
    "\n",
    "* **Node Additive Encoding**: A float vector the length of the number of targets you are considering. Each value is THE DIFFERENCE between the mean value for that target in THIS NODE and the mean value for that target IN THE PARENT of this node. For root nodes, which have no parents, the additive encoding is simply th mean value across the entire dataset. (As if the mean of a hypothetical parent would have been 0). This encoding represents the marginal effect of each node.\n",
    "\n",
    "We should examine if there are any common patterns that appear if we encode many nodes from a forest using each of these representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the sample representations of nodes. \n",
    "# This generates a set of figures demonstrating the existence of node clusters\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# For ease of processing we have to construct dimensionally reduced representations of the encodings. \n",
    "\n",
    "# sample_encoding = forest.node_representation(forest.nodes(root=False),mode='sample')\n",
    "# reduced_sample = PCA(n_components=100).fit_transform(sample_encoding.T)\n",
    "# reduced_node = PCA(n_components=100).fit_transform(sample_encoding)\n",
    "\n",
    "# print(sample_encoding.shape)\n",
    "# print(reduced_sample.shape)\n",
    "# print(reduced_node.shape)\n",
    "\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# sample_agglomeration = dendrogram(linkage(reduced_sample, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "# node_agglomeration = dendrogram(linkage(reduced_node, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Cell Presence in Node (Two-Way Agglomerated)\")\n",
    "# plt.imshow(sample_encoding[node_agglomeration].T[sample_agglomeration].T,cmap='binary',aspect='auto',interpolation='none')\n",
    "# plt.xlabel(\"Cells\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # And here we sort the nodes after they have been clustered (more on the clustering procedure in a bit)\n",
    "\n",
    "# node_cluster_sort = np.argsort([n.split_cluster for n in forest.nodes(root=False)])\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Cell Presence in Node (Clustered)\")\n",
    "# plt.imshow(sample_encoding[node_cluster_sort].T[sample_agglomeration].T,cmap='binary',aspect='auto',interpolation='none')\n",
    "# plt.xlabel(\"Cells\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from sklearn.decomposition import PCA\n",
    "\n",
    "sister_encoding = forest.node_representation(forest.nodes(root=False),mode='sister')\n",
    "reduced_sister = PCA(n_components=100).fit_transform(sister_encoding.T)\n",
    "reduced_node = PCA(n_components=100).fit_transform(sister_encoding)\n",
    "\n",
    "print(sister_encoding.shape)\n",
    "print(reduced_sister.shape)\n",
    "print(reduced_node.shape)\n",
    "\n",
    "# from scipy.cluster.hierarchy import linkage,dendrogram\n",
    "\n",
    "# sister_agglomeration = dendrogram(linkage(reduced_sister, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "# node_agglomeration = dendrogram(linkage(reduced_node, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Sample Presence in Node vs Sister (Two-Way Agglomerated)\")\n",
    "# plt.imshow(sister_encoding[node_agglomeration].T[sister_agglomeration].T,cmap='bwr',aspect='auto',interpolation='none')\n",
    "# plt.xlabel(\"Samples\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Sample Presence in Node vs Sister (Clustered By Gain)\")\n",
    "# plt.imshow(sister_encoding[node_cluster_sort].T[sister_agglomeration].T,cmap='bwr',aspect='auto',interpolation='none')\n",
    "# plt.xlabel(\"Samples\")\n",
    "# plt.ylabel(\"Nodes\")\n",
    "# plt.colorbar()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the construct and agglomerate the additive gain representation \n",
    "\n",
    "\n",
    "feature_encoding = forest.node_representation(forest.nodes(root=False),mode='partial')\n",
    "reduced_feature = PCA(n_components=100).fit_transform(feature_encoding.T)\n",
    "reduced_node = PCA(n_components=100).fit_transform(feature_encoding)\n",
    "\n",
    "feature_agglomeration = dendrogram(linkage(reduced_feature, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "node_agglomeration = dendrogram(linkage(reduced_node, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "node_cluster_sort = np.argsort([n.split_cluster for n in forest.nodes(root=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot the additive gain representation \n",
    "\n",
    "print(feature_encoding.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Target Gain in Node (Double-Agglomerated)\")\n",
    "plt.imshow(feature_encoding[node_agglomeration].T[feature_agglomeration].T,cmap='bwr',interpolation='none',aspect='auto',vmin=-2,vmax=2)\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.colorbar(label=\"Parent Mean - Node Mean (Log TPM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Target Gain in Node (Clustered)\")\n",
    "plt.imshow(feature_encoding[node_cluster_sort].T[feature_agglomeration].T,cmap='bwr',interpolation='none',aspect='auto',vmin=-2,vmax=2)\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.colorbar(label=\"Parent Mean - Node Mean (Log TPM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can look at silhouette plots scores for various node encodings in order to get a feel for whether or not we are adequately clustering them and whether or not the clusters meaningfully exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silhouette Plots For Node Clusters \n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "node_labels = np.array([n.split_cluster for n in forest.nodes(root=False)])\n",
    "\n",
    "# silhouette_scores = silhouette_samples(reduced_node,node_labels,metric='cosine')\n",
    "silhouette_scores = silhouette_samples(feature_encoding,node_labels,metric='euclidean')\n",
    "# silhouette_scores = silhouette_samples(sample_encoding,node_labels,metric='cosine')\n",
    "# silhouette_scores = silhouette_samples(sister_encoding,node_labels,metric='cosine')\n",
    "\n",
    "sorted_silhouette = np.zeros(silhouette_scores.shape)\n",
    "sorted_colors = np.zeros(silhouette_scores.shape)\n",
    "\n",
    "current_index = 0\n",
    "next_index = 0\n",
    "for i in sorted(set(node_labels)):\n",
    "    mask = node_labels == i\n",
    "    selected_values = sorted(silhouette_scores[mask])    \n",
    "    next_index = current_index + np.sum(mask)\n",
    "    sorted_silhouette[current_index:next_index] = selected_values\n",
    "    sorted_colors[current_index:next_index] = i\n",
    "    current_index = next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Silhouette Plots For Nodes Clustered By Gain\")\n",
    "for i,node in enumerate(sorted_silhouette):\n",
    "    plt.plot([0,node],[i,i],color=cm.nipy_spectral(sorted_colors[i] / len(forest.split_clusters)),linewidth=0.5)\n",
    "# plt.scatter(sorted_silhouette,np.arange(len(sorted_silhouette)),s=1)\n",
    "plt.plot([0,0],[0,len(sorted_silhouette)],color='red')\n",
    "plt.xlabel(\"Silhouette Score\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_populations = np.array([n.pop() for n in forest.nodes(root=False)])\n",
    "mask = node_populations > 100\n",
    "\n",
    "\n",
    "feature_encoding = forest.node_representation(forest.nodes(root=False),mode='partial')[mask]\n",
    "reduced_feature = PCA(n_components=100).fit_transform(feature_encoding.T)\n",
    "reduced_node = PCA(n_components=100).fit_transform(feature_encoding)\n",
    "\n",
    "\n",
    "feature_agglomeration = dendrogram(linkage(reduced_feature, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "node_agglomeration = dendrogram(linkage(reduced_node, metric='cosine', method='average'), no_plot=True)['leaves']\n",
    "\n",
    "node_cluster_sort = np.argsort(np.array([n.split_cluster for n in forest.nodes(root=False)])[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(feature_encoding.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Target Gain in Node (Double-Agglomerated)\")\n",
    "plt.imshow(feature_encoding[node_agglomeration].T[feature_agglomeration].T,cmap='bwr',interpolation='none',aspect='auto',vmin=-2,vmax=2)\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.colorbar(label=\"Parent Mean - Node Mean (Log TPM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Target Gain in Node (Clustered)\")\n",
    "plt.imshow(feature_encoding[node_cluster_sort].T[feature_agglomeration].T,cmap='bwr',interpolation='none',aspect='auto',vmin=-2,vmax=2)\n",
    "plt.xlabel(\"Genes\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.colorbar(label=\"Parent Mean - Node Mean (Log TPM)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "node_labels = np.array([n.split_cluster for n in forest.nodes(root=False)])[mask]\n",
    "\n",
    "# silhouette_scores = silhouette_samples(reduced_node,node_labels,metric='cosine')\n",
    "silhouette_scores = silhouette_samples(feature_encoding,node_labels,metric='euclidean')\n",
    "# silhouette_scores = silhouette_samples(sample_encoding,node_labels,metric='cosine')\n",
    "# silhouette_scores = silhouette_samples(sister_encoding,node_labels,metric='cosine')\n",
    "\n",
    "sorted_silhouette = np.zeros(silhouette_scores.shape)\n",
    "sorted_colors = np.zeros(silhouette_scores.shape)\n",
    "\n",
    "current_index = 0\n",
    "next_index = 0\n",
    "for i in sorted(set(node_labels)):\n",
    "    mask = node_labels == i\n",
    "    selected_values = sorted(silhouette_scores[mask])    \n",
    "    next_index = current_index + np.sum(mask)\n",
    "    sorted_silhouette[current_index:next_index] = selected_values\n",
    "    sorted_colors[current_index:next_index] = i\n",
    "    current_index = next_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Silhouette Plots For Nodes Clustered By Gain\")\n",
    "for i,node in enumerate(sorted_silhouette):\n",
    "    plt.plot([0,node],[i,i],color=cm.nipy_spectral(sorted_colors[i] / len(forest.split_clusters)),linewidth=0.5)\n",
    "# plt.scatter(sorted_silhouette,np.arange(len(sorted_silhouette)),s=1)\n",
    "plt.plot([0,0],[0,len(sorted_silhouette)],color='red')\n",
    "plt.xlabel(\"Silhouette Score\")\n",
    "plt.ylabel(\"Nodes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_node = TSNE(n_components=2,metric='cosine').fit_transform(reduced_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(reduced_node[node_agglomeration][:,:20],aspect='auto',cmap='bwr',vmin=-20,vmax=20,interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(*trans_node.T,s=2,c=node_labels,cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "for i in range(5,50,5):\n",
    "\n",
    "    node_labels = KMeans(i).fit_predict(reduced_node[:,:20])\n",
    "        \n",
    "    silhouette_scores = silhouette_samples(feature_encoding,node_labels,metric='cosine')\n",
    "\n",
    "    sorted_silhouette = np.zeros(silhouette_scores.shape)\n",
    "    sorted_colors = np.zeros(silhouette_scores.shape)\n",
    "\n",
    "    current_index = 0\n",
    "    next_index = 0\n",
    "    for i in sorted(set(node_labels)):\n",
    "        mask = node_labels == i\n",
    "        selected_values = sorted(silhouette_scores[mask])    \n",
    "        next_index = current_index + np.sum(mask)\n",
    "        sorted_silhouette[current_index:next_index] = selected_values\n",
    "        sorted_colors[current_index:next_index] = i\n",
    "        current_index = next_index\n",
    "        \n",
    "        \n",
    "    plt.figure()\n",
    "    plt.title(\"Silhouette Plots For Nodes Clustered By Gain\")\n",
    "    for i,node in enumerate(sorted_silhouette):\n",
    "        plt.plot([0,node],[i,i],color=cm.nipy_spectral(sorted_colors[i] / len(forest.split_clusters)),linewidth=0.5)\n",
    "    # plt.scatter(sorted_silhouette,np.arange(len(sorted_silhouette)),s=1)\n",
    "    plt.plot([0,0],[0,len(sorted_silhouette)],color='red')\n",
    "    plt.xlabel(\"Silhouette Score\")\n",
    "    plt.ylabel(\"Nodes\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(clustered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clustered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optics_sort = np.argsort(clustered)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(reduced_node[optics_sort][:,:20],aspect='auto',cmap='bwr',vmin=-20,vmax=20,interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additive mean reduction\n"
     ]
    }
   ],
   "source": [
    "feature_encoding = forest.node_representation(forest.nodes(root=False),mode='additive_mean')\n",
    "labels = np.array([n.split_cluster for n in forest.nodes(root=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13982, 351)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_encoding.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0.016559641797076505)\n",
      "(2, 0.026719961011696415)\n",
      "(3, 0.06821156766792495)\n",
      "(4, 0.010066074929283925)\n",
      "(5, 0.09240248073391005)\n",
      "(6, 0.025061590307325306)\n",
      "(7, 0.02991602035615037)\n",
      "(8, 0.0353980649232254)\n",
      "(9, 0.03799498937860699)\n",
      "(10, 0.010433189810988633)\n",
      "(11, 0.04613366957511943)\n",
      "(12, 0.036096933258465906)\n",
      "(13, 0.018153790308255306)\n",
      "(14, 0.09872839314956372)\n",
      "(15, 0.028664263348692515)\n",
      "(16, 0.03513532089474127)\n",
      "(17, 0.02862872277066524)\n",
      "(18, 0.05273124479343409)\n",
      "(19, 0.07982630344261693)\n",
      "(20, 0.04620545624633957)\n",
      "(21, 0.016000652388528186)\n",
      "(22, 0.027374834552137576)\n",
      "(23, 0.005378702338809322)\n",
      "(24, 0.05956778562472024)\n",
      "(25, 0.070170598958087)\n",
      "(26, 0.03685004444040585)\n",
      "(27, 0.038480988056391524)\n",
      "(28, 0.007310224725935504)\n",
      "(29, 0.011195267947414662)\n",
      "(30, 0.009261578022057989)\n",
      "(31, 0.037641602599044345)\n",
      "(32, 0.04525645099510132)\n",
      "(33, 0.0263833937966067)\n",
      "(34, 0.01577973941522759)\n",
      "(35, 0.05288525227299987)\n",
      "(36, 0.02105744470411041)\n",
      "(37, 0.04311471398790514)\n",
      "(38, 0.010435361956718195)\n",
      "Remaining: 0.03722996474678492\n",
      "All:0.06464032226755297\n"
     ]
    }
   ],
   "source": [
    "remaining = 0\n",
    "\n",
    "for cluster in sorted(list(set(labels))):\n",
    "    mask = labels == cluster\n",
    "    means = np.mean(feature_encoding[mask],axis=0)\n",
    "    residuals = feature_encoding[mask] - means\n",
    "    mse = np.sum(np.power(residuals,2)) / (np.sum(mask) * feature_encoding.shape[1])\n",
    "    remaining += (np.sum(mask) / feature_encoding.shape[0]) * mse\n",
    "    print((cluster,mse))\n",
    "    \n",
    "means = np.mean(feature_encoding,axis=0)\n",
    "residuals = feature_encoding - means\n",
    "mse = np.sum(np.power(residuals,2)) / (feature_encoding.shape[0] * feature_encoding.shape[1])\n",
    "print(f\"Remaining: {remaining}\")\n",
    "print(f\"All:{mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_reader_utils import fast_knn,hacked_louvain\n",
    "\n",
    "shuffled = feature_encoding.copy()\n",
    "\n",
    "for f in shuffled.T:\n",
    "    np.random.shuffle(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "relabel = hacked_louvain(fast_knn(shuffled,50))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "1\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "2\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "3\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "4\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "5\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "6\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "7\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "8\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "9\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "10\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "11\n",
      "\n",
      "\n",
      "Searching for partition\n",
      "Louvain: (13982,)\n",
      "12\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2d39e3cc6a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrelabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhacked_louvain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfast_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/battle/rf_5/src/python/tree_reader_utils.py\u001b[0m in \u001b[0;36mfast_knn\u001b[0;34m(elements, k, neighborhood_fraction, metric)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 anchor_distances = cdist(elements[anchor].reshape(\n\u001b[0;32m--> 220\u001b[0;31m                     1, -1), elements, metric=metric)[0]\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# print(anchor_distances.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(XA, XB, metric, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m             cdist_fn = getattr(_distance_wrap,\n\u001b[1;32m   2770\u001b[0m                                \"cdist_%s_%s_wrap\" % (metric_name, typ))\n\u001b[0;32m-> 2771\u001b[0;31m             \u001b[0mcdist_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "remaining_sims = []\n",
    "\n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    \n",
    "    shuffled = feature_encoding.copy()\n",
    "\n",
    "    for f in shuffled.T:\n",
    "        np.random.shuffle(f)\n",
    "\n",
    "    relabel = hacked_louvain(fast_knn(shuffled,50))\n",
    "\n",
    "    remaining = 0\n",
    "    for cluster in sorted(list(set(relabel))):\n",
    "        mask = relabel == cluster\n",
    "        means = np.mean(shuffled[mask],axis=0)\n",
    "        residuals = shuffled[mask] - means\n",
    "        mse = np.sum(np.power(residuals,2)) / (np.sum(mask) * shuffled.shape[1])\n",
    "        remaining += (np.sum(mask) / shuffled.shape[0]) * mse\n",
    "#         print((cluster,mse))\n",
    "    remaining_sims.append(remaining)\n",
    "    \n",
    "means = np.mean(shuffled,axis=0)\n",
    "residuals = shuffled - means\n",
    "mse = np.sum(np.power(residuals,2)) / (shuffled.shape[0] * shuffled.shape[1])\n",
    "print(f\"Remaining: {remaining}\")\n",
    "print(f\"All:{mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.069990830860928e-08"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(remaining_sims)\n",
    "# np.mean(remaining_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05971537755354919,\n",
       " 0.05961775082241294,\n",
       " 0.059816129397441464,\n",
       " 0.05987840564796268,\n",
       " 0.05987251926929091,\n",
       " 0.05943743881797868,\n",
       " 0.059777988404586146,\n",
       " 0.06001173201954825,\n",
       " 0.05975851649985739,\n",
       " 0.059672617866716224,\n",
       " 0.05976588750782693,\n",
       " 0.05990828552112961]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06315214326262976"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
